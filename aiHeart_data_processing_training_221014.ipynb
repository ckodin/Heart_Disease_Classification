{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14b624b5",
   "metadata": {},
   "source": [
    "# AiHeart : Heart Disease Classification - Cleveland"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80554004",
   "metadata": {},
   "source": [
    "**Table of Content**\n",
    "\n",
    "1. [Project goal](#chapter1)\n",
    "2. [Dataset](#chapter2)\n",
    "3. [Data preprocessing](#chapter3)\n",
    "4. [Baseline modelling](#chapter4)\n",
    "    * [4.1 Baseline modelling results](#chapter41)\n",
    "5. [Optimizing the Hyperparameters](#chapter5)\n",
    "    * [5.1 Linear regression](#chapter51)\n",
    "        * [5.1.1 Result Linear regression](#chapter511)\n",
    "        * [5.1.2 Feature selection for Linear regression](#chapter512)\n",
    "    * [5.2 DT](#chapter52)\n",
    "        * [5.2.1 Result DT](#chapter521)\n",
    "        * [5.2.2 Feature selection for DT](#chapter522)\n",
    "    * [5.3 RF](#chapter53)\n",
    "        * [5.3.1 Result RF](#chapter531)\n",
    "        * [5.3.2 Feature selction for RF](#chapter532)\n",
    "    * [5.4 KNN](#chapter54)\n",
    "        * [5.4.1 Result KNN](#chapter541)\n",
    "    * [5.5 SVM](#chapter55)\n",
    "        * [5.5.1 Result SVM](#chapter551)\n",
    "        * [5.5.2 Feature selection for SVM](#chapter552)\n",
    "    * [5.6 Gradient Boosted Tree](#chapter56)\n",
    "        * [5.6.1 Result Gradient Boosted Tree](#chapter561)\n",
    "        * [5.6.2 Feature selection for Boosted Tree](#chapter562)\n",
    "    * [5.7 XGBoost](#chapter57)\n",
    "        * [5.7.1 Result XGBoost](#chapter571)\n",
    "    * [5.8 Perceptron](#chapter58)\n",
    "        * [5.8.1 Result Perceptron](#chapter581)\n",
    "6. [Result optimization](#chapter6)\n",
    "    * [6.1 Choice of best optimizer](#chapter61)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b71926",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182a911",
   "metadata": {},
   "source": [
    "# 1. Project goal <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681efe8e",
   "metadata": {},
   "source": [
    "- Given clinical parameters about a patient in a primary care setting in the north of Sweden, predict if a patient has Heart Disease or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934f63b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9f9d3",
   "metadata": {},
   "source": [
    "# 2. Dataset <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16386174",
   "metadata": {},
   "source": [
    "Dataset: UCI Heart Disease dataset available at the UCI Machine Learning data repository - http://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "\n",
    "We decided to use only the Cleveland dataset (explanation in the report).\n",
    "\n",
    "\n",
    "### Features in Dataset\n",
    "- There are 14 features in the original Cleveland dataset\n",
    "1. `age`: Age of the patient in years\n",
    "2. `sex`: 1 = Male, 0 = Female\n",
    "3. `cp`: chest pain type, 1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptomatic\n",
    "4. `trestbps`: resting blood pressure in mmHg on admission to the hospital\n",
    "5. `chol`: serum cholesterol in mg/dl\n",
    "6. `fbs`: if fasting blood sugar > 120 mg/dl, 1 = true, 0 = false\n",
    "7. `restecg`: resting electrocardiographic results, 0 = normal, 1 = having ST-T wave abnormality, 2 = probable or definite left ventricular hypertrophy by Estes' criteria\n",
    "8. `thalach`: maximum heart rate achieved\n",
    "9. `exang`: exercise-induced angina, 1 = yes, 0 = no\n",
    "10. `oldpeak`: ST depression induced by exercise relative to rest\n",
    "11. `slope`: the slope of the peak exercise ST segment, 1 = upsloping, 2 = flat, 3 = downsloping\n",
    "12. `ca`: number of major vessels (0-3) colored by fluoroscopy\n",
    "13. `thal`: defect type, 3 = normal, 6 = fixed defect, 7 = reversible defect\n",
    "14. `num`: diagnosis of heart disease (angiographic disease status)\n",
    "\n",
    "### Data type\n",
    "These are the features according to data type:\n",
    "\n",
    "- Categorical features: `sex`, `cp`, `restecg`, `slope`, `ca`, `thal`\n",
    "- Binary features: `exang`, `fbs`, `num`\n",
    "- Numerical features: `age`, `trestbps`, `chol`, `thalach`, `oldpeak`\n",
    "\n",
    "### Class Label\n",
    "- The predicted class label is `num` that we will replace it with the name `target` \n",
    "- The \"goal\" of the application refers to the presence of Heart Disease in the patient. As the physicians are only interested in knowing if the patient is sick or not, we decided to create a **binary classification model** only predicting the presence of Heart Disease, e.i. 0 = no presence of Heart Disease, and 1 (including 1,2,3,4 values) = presence of Heart Disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905b95b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631c093",
   "metadata": {},
   "source": [
    "# 3. Data preprocessing <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1f47f",
   "metadata": {},
   "source": [
    "- There are 303 records in this dataset\n",
    "- We decided to exclude the variables `ca` and `thal` from our application (due to medical procedures reasons, see report).\n",
    "- Visual inspection of the dataframe shows there are 6 missing values. These are in `ca`,`thal` columns, but as we will drop these columns, it does not impact the final dataset.\n",
    "- That's why we do not need to handle any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be6508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafd6878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0    63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1    67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2    67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3    37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4    41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "298  45.0  1.0  1.0     110.0  264.0  0.0      0.0    132.0    0.0      1.2   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "301  57.0  0.0  2.0     130.0  236.0  0.0      2.0    174.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope  target  \n",
       "0      3.0       0  \n",
       "1      2.0       2  \n",
       "2      2.0       1  \n",
       "3      3.0       0  \n",
       "4      1.0       0  \n",
       "..     ...     ...  \n",
       "298    2.0       1  \n",
       "299    2.0       2  \n",
       "300    2.0       3  \n",
       "301    2.0       1  \n",
       "302    1.0       0  \n",
       "\n",
       "[303 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(\"processed.cleveland.csv\")\n",
    "df.drop([\"ca\", \"thal\"], axis=1, inplace=True)\n",
    "df.rename(columns={\"num\": \"target\"}, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c763947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that there are no null values that our visual inpsection missed\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f9d8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change target labels to 1 and 0 to create a binary classification problem.\n",
    "df[\"target\"] = df[\"target\"].replace([2, 3, 4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6dc46e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         float64\n",
       "sex         float64\n",
       "cp          float64\n",
       "trestbps    float64\n",
       "chol        float64\n",
       "fbs         float64\n",
       "restecg     float64\n",
       "thalach     float64\n",
       "exang       float64\n",
       "oldpeak     float64\n",
       "slope       float64\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694adbc1",
   "metadata": {},
   "source": [
    "#### The variables types are\n",
    "\n",
    "1. Binary: `fbs`, `exang` , `target`\n",
    "2. Categorical: `cp`, `restecg`, `slope`, `sex`\n",
    "3. Continuous: `age`, `trestbps`, `chol` , `thalac`, `oldpeak`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3642ce12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          float64\n",
       "sex         category\n",
       "cp          category\n",
       "trestbps     float64\n",
       "chol         float64\n",
       "fbs             bool\n",
       "restecg     category\n",
       "thalach      float64\n",
       "exang           bool\n",
       "oldpeak      float64\n",
       "slope       category\n",
       "target          bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to appropriate datatype. \n",
    "df.cp = df.cp.astype(\"category\")\n",
    "df.restecg = df.restecg.astype(\"category\")\n",
    "df.slope = df.slope.astype(\"category\")\n",
    "df.sex = df.sex.astype(\"category\")\n",
    "df.fbs = df.fbs.astype(\"bool\")\n",
    "df.exang = df.exang.astype(\"bool\")\n",
    "df.target = df.target.astype(\"bool\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7503899e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check numeric variables for outliers\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,\n",
    "                                             ncols=2,\n",
    "                                             figsize=(10, 5))\n",
    "ax1.boxplot(df['age'], labels=['age']);\n",
    "ax2.boxplot([df['trestbps'], df['thalach']], labels=['trestbps', 'thalach']);\n",
    "ax3.boxplot(df['chol'], labels=['chol']);\n",
    "ax4.boxplot(df['oldpeak'], labels=['oldpeak']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ece56",
   "metadata": {},
   "source": [
    "- There are some outliers for `trestbps`, `thalach`, `chol` and `oldpeak`\n",
    "- Verified with medical doctor - values are plausible hence these values are kept in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e02e86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    164\n",
       "True     139\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check class balance - 164 patients have label False ( 0, no heart disease), 139 patients have label True ( 1, heart disease)\n",
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60a51b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class balance\n",
    "df[\"target\"].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e956bfd",
   "metadata": {},
   "source": [
    "### Preparing dataframes for Classification Tasks\n",
    "\n",
    "This step is to **transform the pandas DataFrame into numerical Numpy arrays**, so that they can be processed by the packages in `sklearn`. At this stage, we need to **encode the categorical features** ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909bc60",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77bcd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding for categorical variables\n",
    "df_processed = pd.get_dummies(df, columns=[\"sex\",\"cp\",\"restecg\",\"slope\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a355e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>cp_4.0</th>\n",
       "      <th>restecg_0.0</th>\n",
       "      <th>restecg_1.0</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>45.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>False</td>\n",
       "      <td>132.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>True</td>\n",
       "      <td>141.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.4</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>False</td>\n",
       "      <td>115.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>False</td>\n",
       "      <td>174.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>False</td>\n",
       "      <td>173.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  trestbps   chol    fbs  thalach  exang  oldpeak  target  sex_0.0  \\\n",
       "0    63.0     145.0  233.0   True    150.0  False      2.3   False        0   \n",
       "1    67.0     160.0  286.0  False    108.0   True      1.5    True        0   \n",
       "2    67.0     120.0  229.0  False    129.0   True      2.6    True        0   \n",
       "3    37.0     130.0  250.0  False    187.0  False      3.5   False        0   \n",
       "4    41.0     130.0  204.0  False    172.0  False      1.4   False        1   \n",
       "..    ...       ...    ...    ...      ...    ...      ...     ...      ...   \n",
       "298  45.0     110.0  264.0  False    132.0  False      1.2    True        0   \n",
       "299  68.0     144.0  193.0   True    141.0  False      3.4    True        0   \n",
       "300  57.0     130.0  131.0  False    115.0   True      1.2    True        0   \n",
       "301  57.0     130.0  236.0  False    174.0  False      0.0    True        1   \n",
       "302  38.0     138.0  175.0  False    173.0  False      0.0   False        0   \n",
       "\n",
       "     sex_1.0  cp_1.0  cp_2.0  cp_3.0  cp_4.0  restecg_0.0  restecg_1.0  \\\n",
       "0          1       1       0       0       0            0            0   \n",
       "1          1       0       0       0       1            0            0   \n",
       "2          1       0       0       0       1            0            0   \n",
       "3          1       0       0       1       0            1            0   \n",
       "4          0       0       1       0       0            0            0   \n",
       "..       ...     ...     ...     ...     ...          ...          ...   \n",
       "298        1       1       0       0       0            1            0   \n",
       "299        1       0       0       0       1            1            0   \n",
       "300        1       0       0       0       1            1            0   \n",
       "301        0       0       1       0       0            0            0   \n",
       "302        1       0       0       1       0            1            0   \n",
       "\n",
       "     restecg_2.0  slope_1.0  slope_2.0  slope_3.0  \n",
       "0              1          0          0          1  \n",
       "1              1          0          1          0  \n",
       "2              1          0          1          0  \n",
       "3              0          0          0          1  \n",
       "4              1          1          0          0  \n",
       "..           ...        ...        ...        ...  \n",
       "298            0          0          1          0  \n",
       "299            0          0          1          0  \n",
       "300            0          0          1          0  \n",
       "301            1          0          1          0  \n",
       "302            0          1          0          0  \n",
       "\n",
       "[303 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "847703b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric the columns that are binary\n",
    "df_processed[\"fbs\"] = df_processed[\"fbs\"].astype(int)\n",
    "df_processed[\"exang\"] = df_processed[\"exang\"].astype(int)\n",
    "df_processed[\"target\"] = df_processed[\"target\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ed952",
   "metadata": {},
   "source": [
    "### Choose features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d08aca",
   "metadata": {},
   "source": [
    "**Correlation Matrix with Heatmap**\n",
    "\n",
    "Correlation indicates how the features are related to each other or to the target variable. The correlation may be positive (increase in one value of the feature increases the value of the target variable) or negative (increase in one value of the feature decreases the value of the target variable). Heatmap makes it easy to classify the features that are most relevant to the target variable, and we will plot the associated features of the heatmap using the seaborn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1e259dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df_processed.corr(),annot=True,cmap=\"magma\",fmt=\".2f\", linewidths=.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcec547",
   "metadata": {},
   "source": [
    "- From the correlation matrix it seems that the `exang`, `oldpeak`, `sex`, `age`, `slope_2`and `cp_4` are more correlated with the `target `(the presense of heart disease or not) \n",
    "- `exang`: Exercise induced angina (1 = yes; 0 = no)\n",
    "- `oldpeak`: ST depression induced by exercise relative to rest \n",
    "- `slope_2`:the slope of the peak exercise ST segment — 2: upsloping\n",
    "- `cp_4`:chest pain type - 4: typical angina\n",
    "- `sex`, \n",
    "- `age`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280843ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cba3eae",
   "metadata": {},
   "source": [
    "# 4. Baseline modelling <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f90907",
   "metadata": {},
   "source": [
    "- We have referred to the flowchart provided in the following site that gave us a rough guide on how to approach problems concerning which estimators to try on our data. https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "- Models we have used initially are the following: Logistic Regression, DT, RF,KNN,SVC, Gradient Boosted Tree (GBDT), Extreme Gradient Boosting (XGBoost), and AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c34598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5cf037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining feature vector and class labels\n",
    "X = df_processed.drop(\"target\", axis=1)\n",
    "y = df_processed[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b5c3351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' 'trestbps' 'chol' 'fbs' 'thalach' 'exang' 'oldpeak' 'sex_0.0'\n",
      " 'sex_1.0' 'cp_1.0' 'cp_2.0' 'cp_3.0' 'cp_4.0' 'restecg_0.0' 'restecg_1.0'\n",
      " 'restecg_2.0' 'slope_1.0' 'slope_2.0' 'slope_3.0']\n"
     ]
    }
   ],
   "source": [
    "# Finally, we need transform from Pandas DataFrame to numerical Arrays, and store the column names\n",
    "data_X = X.values\n",
    "data_y = y.values\n",
    "\n",
    "data_colnames = X.columns.values\n",
    "print(data_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a420934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation of feature vector since SVC and KNN require normalisation\n",
    "scaler = MinMaxScaler()\n",
    "data_X = scaler.fit_transform(data_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899f60",
   "metadata": {},
   "source": [
    "### Final feature matrix $\\mathbf{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f040ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70833333, 0.48113208, 0.24429224, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.79166667, 0.62264151, 0.3652968 , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.79166667, 0.24528302, 0.23515982, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.58333333, 0.33962264, 0.01141553, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.58333333, 0.33962264, 0.25114155, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.1875    , 0.41509434, 0.11187215, ..., 1.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa8cf18",
   "metadata": {},
   "source": [
    "### Final target array $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d718b2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a9404",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "As the dataset is pretty small (normally < 300), a single train-test split has a significant problem. Normally there is a fraction of the dataset that is a holdout for testing and never goes in the training process, but with a small dataset, we want to use as much data as possible to train our model.\n",
    "\n",
    "Cross-validation (CV) is a strategy to solve the problem of single train-test split and **the correct approach** to evaluate model performance for small datasets. The CV partitions a dataset into `k` folds or groups. It then uses all but one of the folds as training data and the final fold as test data. In subsequent loops, CV uses the other folds, one at a time, as test set, while the remaining folds form the training set. Statistics are measured for each loop, and the average accuracy etc, is finally calculated over all loops.\n",
    "\n",
    "This also means that a CV creates `k` different classification models instead of only one. It might be time-consuming for classifiers that take a lot of time to train or large datasets.\n",
    "\n",
    "Yet another consideration when using CV is when the target classes are very imbalanced, then **stratified k-fold cross validation** is a better option. In our dataset, however, the sick/non-sick people are roughly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833cd2bd",
   "metadata": {},
   "source": [
    "### Baseline model evaluation with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94368737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate models, metrics and evaluation statistics\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"GBDT\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"SVM\": SVC()}\n",
    "\n",
    "\n",
    "metrics = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\", \"roc_auc\"]\n",
    "\n",
    "result_eval = pd.DataFrame({ \"classifier_name\":[],\n",
    "                                    \"fit_time\": [],\n",
    "                                    \"score_time\": [],\n",
    "                                    \"test_accuracy\": [],\n",
    "                                    \"test_precision_macro\": [],\n",
    "                                    \"test_recall_macro\": [],\n",
    "                                    \"test_f1_macro\": []\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9e1e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing and evaluating models \n",
    "for name, classifier in models.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "        \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_this_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_this_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    this_result = pd.DataFrame(dict_this_result)\n",
    "    result_eval = pd.concat([result_eval, this_result], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb44fb6",
   "metadata": {},
   "source": [
    "## 4.1. Baseline model result <a class=\"anchor\" id=\"chapter41\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bf4fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.778852</td>\n",
       "      <td>0.779359</td>\n",
       "      <td>0.776631</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.882522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.683224</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.678981</td>\n",
       "      <td>0.679004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.071501</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>0.769071</td>\n",
       "      <td>0.770251</td>\n",
       "      <td>0.767226</td>\n",
       "      <td>0.766973</td>\n",
       "      <td>0.852734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.762568</td>\n",
       "      <td>0.763770</td>\n",
       "      <td>0.763814</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>0.807423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.775683</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.777691</td>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.852366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.047196</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.765519</td>\n",
       "      <td>0.767636</td>\n",
       "      <td>0.760961</td>\n",
       "      <td>0.761306</td>\n",
       "      <td>0.840292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.772186</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.769545</td>\n",
       "      <td>0.768755</td>\n",
       "      <td>0.822226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.742459</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.738692</td>\n",
       "      <td>0.736954</td>\n",
       "      <td>0.796248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier_name  fit_time  score_time  test_accuracy  \\\n",
       "0  Logistic Regression  0.003354    0.002045       0.778852   \n",
       "1                   DT  0.000802    0.001647       0.683224   \n",
       "2                   RF  0.071501    0.010982       0.769071   \n",
       "3                  KNN  0.000168    0.009762       0.762568   \n",
       "4                  SVM  0.002743    0.003600       0.775683   \n",
       "5                 GBDT  0.047196    0.002179       0.765519   \n",
       "6              XGBoost  0.030101    0.003371       0.772186   \n",
       "7             AdaBoost  0.035655    0.008534       0.742459   \n",
       "\n",
       "   test_precision_macro  test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0              0.779359           0.776631       0.776390      0.882522  \n",
       "1              0.682273           0.679004       0.678981      0.679004  \n",
       "2              0.770251           0.767226       0.766973      0.852734  \n",
       "3              0.763770           0.763814       0.761660      0.807423  \n",
       "4              0.777530           0.777691       0.774883      0.852366  \n",
       "5              0.767636           0.760961       0.761306      0.840292  \n",
       "6              0.776667           0.769545       0.768755      0.822226  \n",
       "7              0.744710           0.738692       0.736954      0.796248  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d7c67",
   "metadata": {},
   "source": [
    "From the baseline testing and the evaluation regarding recall and F1 (se explanation in report) of the different classifier  that we chose, one can see that som classifiers performs better such as `Logistic Regression`, `XGBoost`, `SVM`, `Random Forest` in comparison to the others `GBDT`, `AdaBoost`, then `KNN` and finally `Decision Tree`.\n",
    "\n",
    "So let's start optimizing the hyperparameters in the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33740ae1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bc412",
   "metadata": {},
   "source": [
    "# 5. Optimizing the Hyperparameters <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf1ecc",
   "metadata": {},
   "source": [
    "We chose to optimize `Logistic Regression`, `Decision Tree`, `Random Forest`, `KNN` and `SVC` as the most traditional classifiers we learned about in our courses. We also thought to use the `Graded Boosted Tree` and `XGBoost`as we have found after research that they can provide good results. However, we skipped `AdaBoost` as it has not shown some outstanding results in the baseline modeling. Finally, we decided to use also a simple Deep Learning model, `Perceptron`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a815c50",
   "metadata": {},
   "source": [
    "Setting up for optimizing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e288a5a",
   "metadata": {},
   "source": [
    "## 5.1 Logistic Regression <a class=\"anchor\" id=\"chapter51\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bebffbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "                   random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20,\n",
       "                   param_distributions={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "                   random_state=42, verbose=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20,\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'solver': ['liblinear']},\n",
       "                   random_state=42, verbose=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n",
    "                \"solver\": [\"liblinear\"]}\n",
    "\n",
    "rs_log_reg = RandomizedSearchCV(LogisticRegression(), \n",
    "                                param_distributions=log_reg_grid,\n",
    "                               cv=5,\n",
    "                               n_iter=20,\n",
    "                               verbose=True, \n",
    "                               random_state=42)\n",
    "\n",
    "rs_log_reg.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03f1c765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'liblinear', 'C': 11.288378916846883}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52a7dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=11.288378916846883, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=11.288378916846883, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=11.288378916846883, solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_log_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5595dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.791967</td>\n",
       "      <td>0.794689</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.78926</td>\n",
       "      <td>0.881489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier_name  fit_time  score_time  test_accuracy  \\\n",
       "0  Logistic Regression  0.000593    0.001814       0.791967   \n",
       "\n",
       "   test_precision_macro  test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0              0.794689           0.789388        0.78926      0.881489  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"Logistic Regression\": LogisticRegression(C=11.288378916846883, solver='liblinear')}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_lr_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_lr_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_lr_result)\n",
    "    df_finalresult = pd.DataFrame(dict_lr_result)\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a3737",
   "metadata": {},
   "source": [
    "### 5.1.1 Result for optimized Logistic regression <a class=\"anchor\" id=\"chapter511\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24246bb7",
   "metadata": {},
   "source": [
    "* Accuracy = 0.791\n",
    "* Precision = 0.795\n",
    "* Recall = 0.789\n",
    "* F1 = 0.789\n",
    "* AUC = 0.881\n",
    "\n",
    "With hyperparameters setting: \n",
    "- C = 11.288\n",
    "- solver = 'liblinear'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271133b",
   "metadata": {},
   "source": [
    "### 5.1.2 Feature selection for Logistic regression <a class=\"anchor\" id=\"chapter512\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9452e2",
   "metadata": {},
   "source": [
    "We decided to try a feature selection algorithm (RFE) to see if by excluding some of the features the performance parameters could improve. We tried different numbers of features and the best was chosen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3195ef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.365297</td>\n",
       "      <td>0.282443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.235160</td>\n",
       "      <td>0.442748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3    4         5    6    7    8    9\n",
       "0  0.708333  0.481132  0.244292  0.603053  0.0  0.370968  0.0  1.0  0.0  0.0\n",
       "1  0.791667  0.622642  0.365297  0.282443  1.0  0.241935  0.0  1.0  1.0  1.0\n",
       "2  0.791667  0.245283  0.235160  0.442748  1.0  0.419355  0.0  1.0  1.0  1.0\n",
       "3  0.166667  0.339623  0.283105  0.885496  0.0  0.564516  0.0  1.0  0.0  0.0\n",
       "4  0.250000  0.339623  0.178082  0.770992  0.0  0.225806  1.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature selecting and visualizing the new dataset with only selected features, for Logistic Regression\n",
    "from sklearn.feature_selection import RFE\n",
    "select_lr = RFE(LogisticRegression(), n_features_to_select= 10)\n",
    "X_newlr = select_lr.fit_transform(data_X, data_y)\n",
    "\n",
    "pd.DataFrame(X_newlr).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c037b8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'thalach',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'sex_0.0',\n",
       " 'sex_1.0',\n",
       " 'cp_4.0',\n",
       " 'slope_2.0']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Listing the columns that represent the selected features\n",
    "list(np.take(X.columns, np.where(select_lr.support_ == True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e1bbc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, 10,  1,  1,  1,  1,  1,  4,  6,  5,  1,  3,  7,  8,  2,\n",
       "        1,  9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See how each of the columns were ranked by RFE\n",
    "select_lr.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fcca9002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thalach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slope_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slope_1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restecg_0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_3.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbs</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Rank\n",
       "0           age     1\n",
       "1      trestbps     1\n",
       "2          chol     1\n",
       "4       thalach     1\n",
       "5         exang     1\n",
       "6       oldpeak     1\n",
       "7       sex_0.0     1\n",
       "8       sex_1.0     1\n",
       "17    slope_2.0     1\n",
       "12       cp_4.0     1\n",
       "16    slope_1.0     2\n",
       "13  restecg_0.0     3\n",
       "9        cp_1.0     4\n",
       "11       cp_3.0     5\n",
       "10       cp_2.0     6\n",
       "14  restecg_1.0     7\n",
       "15  restecg_2.0     8\n",
       "18    slope_3.0     9\n",
       "3           fbs    10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Presenting in a dataframe the ranking of each feature. Features ranked in the 1st place were selected by RFE.\n",
    "#The lower the rank (e.g 11th), the sooner RFE excluded it.\n",
    "selectedfeature_lr = pd.DataFrame({'Feature': list(X.columns),\n",
    "                                 'Rank': select_lr.ranking_})\n",
    "selectedfeature_lr.sort_values(by = 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89bdb0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/304609535.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_lr_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR with RFE</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.805301</td>\n",
       "      <td>0.806232</td>\n",
       "      <td>0.803749</td>\n",
       "      <td>0.803491</td>\n",
       "      <td>0.894094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0     LR with RFE  0.000547    0.001841       0.805301              0.806232   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.803749       0.803491      0.894094  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result for RFE selected features of LR\n",
    "dt_model={\"LR with RFE\": LogisticRegression(C=11.288378916846883, solver='liblinear')}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, X_newlr, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_lr_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_lr_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_lr_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_lr_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601474f",
   "metadata": {},
   "source": [
    "### 5.1.2 Result for optimized Linear regression with feature selection <a class=\"anchor\" id=\"chapter512\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3410eb2",
   "metadata": {},
   "source": [
    "* Accuracy = 0.805\n",
    "* Precision = 0.806\n",
    "* Recall = 0.804\n",
    "* F1 = 0.803\n",
    "* AUC = 0.894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7b1ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64c089",
   "metadata": {},
   "source": [
    "## 5.2 Decision Tree <a class=\"anchor\" id=\"chapter52\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82e24c",
   "metadata": {},
   "source": [
    "Decision Tree(DT) classifier is a kind of classification model and has a flow-chart like tree structure based on if-then statement. In terms of generating the classifier, at first, all training samples are at a root, and then partitioned based on selected attributes (Tree construction). Afterwards, unneccessary branches are identified and removed to decrease outliers (Tree pruning). Finally, by using a test set, the model classifies unknown(test) samples.\n",
    "Advantages of DT would be easy application and implementation, reasonable training time, and the possibility of handling large number of features. However, due to simple decision boundaries, DT has risks of missing data and difficulties on handling complicated relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f934d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7655737704918033"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply grid search to find the best parameters in Decision Tree classifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "dt_params = {\"criterion\":['gini','entropy','log_loss'],\n",
    "             \"splitter\":['best','random'],\n",
    "             \"max_depth\":[2,5,10],\n",
    "             \"min_weight_fraction_leaf\":[0,0.25,0.5],\n",
    "             \"max_features\":['auto','sqrt','log2']          \n",
    "             }\n",
    "dt_grid = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_params, verbose=5, n_jobs=-1)\n",
    "dt_grid.fit(data_X, data_y)\n",
    "dt_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32bd191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'min_weight_fraction_leaf': 0,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2b7f5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, max_features=&#x27;auto&#x27;,\n",
       "                       min_weight_fraction_leaf=0, random_state=42,\n",
       "                       splitter=&#x27;random&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=5, max_features=&#x27;auto&#x27;,\n",
       "                       min_weight_fraction_leaf=0, random_state=42,\n",
       "                       splitter=&#x27;random&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                       min_weight_fraction_leaf=0, random_state=42,\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c8498f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/733267529.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_dt_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.765574</td>\n",
       "      <td>0.778168</td>\n",
       "      <td>0.757116</td>\n",
       "      <td>0.757072</td>\n",
       "      <td>0.809711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0   Decision Tree  0.000714    0.002301       0.765574              0.778168   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.757116       0.757072      0.809711  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"Decision Tree\":DecisionTreeClassifier(max_depth=dt_grid.best_params_['max_depth'], max_features=dt_grid.best_params_['max_features'],\n",
    "                                                 min_weight_fraction_leaf=dt_grid.best_params_['min_weight_fraction_leaf'], splitter=dt_grid.best_params_['splitter'],random_state=42)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_dt_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_dt_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_dt_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_dt_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f04233",
   "metadata": {},
   "source": [
    "### 5.2.1 Result for optimized DT <a class=\"anchor\" id=\"chapter521\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5121ed0e",
   "metadata": {},
   "source": [
    "* Accuracy = 0.766\n",
    "* Precision = 0.778\n",
    "* Recall = 0.757\n",
    "* F1 = 0.757\n",
    "* AUC = 0.809\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46614a8",
   "metadata": {},
   "source": [
    "### 5.2.2 Feature selection for DT <a class=\"anchor\" id=\"chapter522\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "727a8ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restecg_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slope_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thalach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slope_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbs</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_3.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Rank\n",
       "0           age     1\n",
       "13  restecg_0.0     1\n",
       "12       cp_4.0     1\n",
       "11       cp_3.0     1\n",
       "17    slope_2.0     1\n",
       "15  restecg_2.0     1\n",
       "8       sex_1.0     1\n",
       "5         exang     1\n",
       "4       thalach     1\n",
       "2          chol     1\n",
       "1      trestbps     1\n",
       "6       oldpeak     1\n",
       "16    slope_1.0     1\n",
       "10       cp_2.0     2\n",
       "7       sex_0.0     3\n",
       "3           fbs     4\n",
       "14  restecg_1.0     5\n",
       "18    slope_3.0     6\n",
       "9        cp_1.0     7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The logic is described above. Showing only the final dataframe with the rankings for each feature\n",
    "select_dt = RFE(DecisionTreeClassifier(random_state=42), n_features_to_select= 13)\n",
    "X_newdt = select_dt.fit_transform(data_X, data_y)\n",
    "\n",
    "selectedfeature_dt = pd.DataFrame({'Feature': list(X.columns),\n",
    "'Rank': select_dt.ranking_})\n",
    "selectedfeature_dt.sort_values(by = 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afa020c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:298: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'`.\n",
      "  warnings.warn(\n",
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/3174775367.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_dt_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT with RFE</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.752514</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>0.753489</td>\n",
       "      <td>0.751558</td>\n",
       "      <td>0.818561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0     DT with RFE  0.000975    0.002407       0.752514              0.752632   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.753489       0.751558      0.818561  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the results for DT with feature selection\n",
    "dt_model={\"DT with RFE\":DecisionTreeClassifier(max_depth=dt_grid.best_params_['max_depth'], max_features=dt_grid.best_params_['max_features'],\n",
    "                                                 min_weight_fraction_leaf=dt_grid.best_params_['min_weight_fraction_leaf'], splitter=dt_grid.best_params_['splitter'], random_state=42)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, X_newdt, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_dt_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_dt_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_dt_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_dt_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1107d47",
   "metadata": {},
   "source": [
    "### 5.2.2 Result for optimized Decision Tree with feature selection <a class=\"anchor\" id=\"chapter522\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343539b",
   "metadata": {},
   "source": [
    "* Accuracy = 0.753\n",
    "* Precision = 0.753\n",
    "* Recall = 0.753\n",
    "* F1 = 0.752\n",
    "* AUC = 0.819"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c1ec7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a87e5c",
   "metadata": {},
   "source": [
    "## 5.3 Random Forest <a class=\"anchor\" id=\"chapter53\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47196e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        &#x27;n_estimators&#x27;: array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700,\n",
       "       750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        &#x27;n_estimators&#x27;: array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700,\n",
       "       750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'max_depth': [None, 10, 20, 30],\n",
       "                                        'min_samples_leaf': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        'min_samples_split': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        'n_estimators': array([100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650, 700,\n",
       "       750, 800, 850, 900, 950])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check range of best parameters with randomized search CV\n",
    "# This code takes a while to run so I've commented it out\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomized parameters grid \n",
    "rf_rs_params = {\"n_estimators\" : np.arange(100, 1000, 50),\n",
    "                \"max_depth\": [None, 10, 20, 30],\n",
    "                \"min_samples_split\": np.arange(2, 20, 2),\n",
    "                \"min_samples_leaf\": np.arange(1, 20, 2)}\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                    param_distributions=rf_rs_params,\n",
    "                    cv=5,\n",
    "                    n_iter=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# Fit to data\n",
    "rs_rf.fit(data_X, data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c54cad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 17,\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best hyperparameters\n",
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "774f9799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7820765027322404"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57d4ec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 30, 40],\n",
       "                         &#x27;min_samples_leaf&#x27;: array([8, 9]),\n",
       "                         &#x27;min_samples_split&#x27;: array([14, 16]),\n",
       "                         &#x27;n_estimators&#x27;: array([800, 850, 900, 950])},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [20, 30, 40],\n",
       "                         &#x27;min_samples_leaf&#x27;: array([8, 9]),\n",
       "                         &#x27;min_samples_split&#x27;: array([14, 16]),\n",
       "                         &#x27;n_estimators&#x27;: array([800, 850, 900, 950])},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [20, 30, 40],\n",
       "                         'min_samples_leaf': array([8, 9]),\n",
       "                         'min_samples_split': array([14, 16]),\n",
       "                         'n_estimators': array([800, 850, 900, 950])},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use grid search to find best parameters within smaller range of hyperparameters \n",
    "# This code takes a while to run so I've commented it out\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "rf_gs_params = {\"n_estimators\" : np.arange(800, 1000, 50),\n",
    "                \"max_depth\": [20, 30, 40],\n",
    "                \"min_samples_split\": np.arange(14, 18, 2),\n",
    "                \"min_samples_leaf\": np.arange(8, 10, 1)}\n",
    "\n",
    "gs_rf = GridSearchCV(RandomForestClassifier(),\n",
    "                    param_grid=rf_gs_params,\n",
    "                    cv=5, \n",
    "                    verbose=1)\n",
    "\n",
    "gs_rf.fit(data_X, data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5afd777e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 9,\n",
       " 'min_samples_split': 16,\n",
       " 'n_estimators': 850}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fefc4df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=9, min_samples_split=16,\n",
       "                       n_estimators=850)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=30, min_samples_leaf=9, min_samples_split=16,\n",
       "                       n_estimators=850)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=30, min_samples_leaf=9, min_samples_split=16,\n",
       "                       n_estimators=850)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54444908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/32696786.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_rf_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.56394</td>\n",
       "      <td>0.074595</td>\n",
       "      <td>0.765628</td>\n",
       "      <td>0.767169</td>\n",
       "      <td>0.763019</td>\n",
       "      <td>0.762928</td>\n",
       "      <td>0.879638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0   Random Forest   0.56394    0.074595       0.765628              0.767169   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.763019       0.762928      0.879638  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"Random Forest\":RandomForestClassifier(max_depth=30, min_samples_leaf=9,\n",
    "                                                 min_samples_split=16, n_estimators=850)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_rf_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_rf_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_rf_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_rf_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436eb7ac",
   "metadata": {},
   "source": [
    "### 5.3.1 Result for optimized RF <a class=\"anchor\" id=\"chapter531\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d456a",
   "metadata": {},
   "source": [
    "* Accuracy = 0.766\t\n",
    "* Precision = 0.767\n",
    "* Recall = 0.763\n",
    "* F1 = 0.763\n",
    "* AUC = 0.880\n",
    "\n",
    "With hyperparameters setting: \n",
    "- max_depth = 30\n",
    "- min_samples_leaf = 9\n",
    "- min_samples_split = 16\n",
    "- n_estimators = 850"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5480885d",
   "metadata": {},
   "source": [
    "### 5.3.2 Feature selection for optimized RF <a class=\"anchor\" id=\"chapter532\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6130eac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thalach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slope_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slope_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restecg_0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_3.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Rank\n",
       "0           age     1\n",
       "1      trestbps     1\n",
       "2          chol     1\n",
       "4       thalach     1\n",
       "5         exang     1\n",
       "6       oldpeak     1\n",
       "7       sex_0.0     1\n",
       "8       sex_1.0     1\n",
       "17    slope_2.0     1\n",
       "12       cp_4.0     1\n",
       "16    slope_1.0     1\n",
       "11       cp_3.0     2\n",
       "15  restecg_2.0     3\n",
       "13  restecg_0.0     4\n",
       "3           fbs     5\n",
       "10       cp_2.0     6\n",
       "9        cp_1.0     7\n",
       "18    slope_3.0     8\n",
       "14  restecg_1.0     9"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The logic is described above. Showing only the final dataframe with the rankings for each feature\n",
    "select_rf = RFE(RandomForestClassifier(), n_features_to_select= 11)\n",
    "X_newrf = select_rf.fit_transform(data_X, data_y)\n",
    "\n",
    "selectedfeature_rf = pd.DataFrame({'Feature': list(X.columns),\n",
    "                                   'Rank': select_rf.ranking_})\n",
    "selectedfeature_rf.sort_values(by = 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cb25160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/3621171051.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_rf_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF with RFE</td>\n",
       "      <td>0.556614</td>\n",
       "      <td>0.074075</td>\n",
       "      <td>0.775519</td>\n",
       "      <td>0.776366</td>\n",
       "      <td>0.772424</td>\n",
       "      <td>0.773035</td>\n",
       "      <td>0.881546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0     RF with RFE  0.556614    0.074075       0.775519              0.776366   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.772424       0.773035      0.881546  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result for RF with feature selection\n",
    "dt_model={\"RF with RFE\":RandomForestClassifier(max_depth=30, min_samples_leaf=9,\n",
    "                                                 min_samples_split=16, n_estimators=850)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, X_newrf, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_rf_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_rf_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_rf_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_rf_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d425e6c",
   "metadata": {},
   "source": [
    "### 5.3.2 Result for optimized RF with feature selection <a class=\"anchor\" id=\"chapter532\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909cf09",
   "metadata": {},
   "source": [
    "* Accuracy = 0.776\n",
    "* Precision = 0.776\n",
    "* Recall = 0.772\n",
    "* F1 = 0.773\n",
    "* AUC = 0.882"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eebe2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ae1a0",
   "metadata": {},
   "source": [
    "## 5.4 KNN <a class=\"anchor\" id=\"chapter54\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f6d08",
   "metadata": {},
   "source": [
    "K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4917080a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7821857923497267"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=5, n_jobs = -1)\n",
    "g_res = gs.fit(data_X, data_y)\n",
    "g_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8cc34c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'minkowski', 'n_neighbors': 11, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "373a0ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/1616809418.py:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_knn_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.00793</td>\n",
       "      <td>0.782186</td>\n",
       "      <td>0.781741</td>\n",
       "      <td>0.781901</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.845617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0             KNN  0.000262     0.00793       0.782186              0.781741   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.781901       0.780702      0.845617  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"KNN\":KNeighborsClassifier(metric='minkowski', n_neighbors=11,\n",
    "                                                 weights='uniform')}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_knn_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_knn_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_knn_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_knn_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5247241",
   "metadata": {},
   "source": [
    "### 5.4.1 Result for optimized KNN <a class=\"anchor\" id=\"chapter541\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7840be",
   "metadata": {},
   "source": [
    "* Accuracy = 0.782\n",
    "* Precision = 0.782\n",
    "* Recall = 0.782\t\n",
    "* F1 = 0.781\n",
    "* AUC = 0.846\n",
    "\n",
    "With hyperparameters setting: \n",
    "- metric = minkowski\n",
    "- n_neighbors = 11\n",
    "- weights = uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aab336",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7644bf9c",
   "metadata": {},
   "source": [
    "## 5.5 SVM <a class=\"anchor\" id=\"chapter55\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1b983",
   "metadata": {},
   "source": [
    "Support Vector Machine, SVM or SVC, has various hyperparameters. The most important are `C`, `kernel` and `gamma`. I will use the following codes to find which combination of hyperparameters `C`, `kernel` and `gamma` is the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b030d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc= SVC()\n",
    "parameters = {\n",
    "    \"kernel\": [\"linear\",\"rbf\", \"poly\"],\n",
    "    \"C\":[0.1,1,10,100],\n",
    "    \"gamma\": [1,0.1,0.01,0.001],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8d138de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;, &#x27;poly&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001],\n",
       "                         'kernel': ['linear', 'rbf', 'poly']})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GridSearchCV(svc,parameters,cv=5)\n",
    "cv.fit(data_X,data_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa017a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(results):\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,2)} + or -{round(std,2)} for the {params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b82e979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.77 + or -0.05 for the {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.66 + or -0.05 for the {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.73 + or -0.02 for the {'C': 0.1, 'gamma': 1, 'kernel': 'poly'}\n",
      "0.77 + or -0.05 for the {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.78 + or -0.04 for the {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.77 + or -0.05 for the {'C': 0.1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.54 + or -0.01 for the {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 0.1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.77 + or -0.05 for the {'C': 0.1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.54 + or -0.01 for the {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.79 + or -0.07 for the {'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.75 + or -0.03 for the {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.72 + or -0.05 for the {'C': 1, 'gamma': 1, 'kernel': 'poly'}\n",
      "0.79 + or -0.07 for the {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.77 + or -0.05 for the {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.78 + or -0.04 for the {'C': 1, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.79 + or -0.07 for the {'C': 1, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.78 + or -0.04 for the {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 1, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.79 + or -0.07 for the {'C': 1, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.54 + or -0.01 for the {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.77 + or -0.07 for the {'C': 10, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.73 + or -0.05 for the {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.69 + or -0.05 for the {'C': 10, 'gamma': 1, 'kernel': 'poly'}\n",
      "0.77 + or -0.07 for the {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.76 + or -0.03 for the {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.77 + or -0.03 for the {'C': 10, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.77 + or -0.07 for the {'C': 10, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.79 + or -0.05 for the {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 10, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.77 + or -0.07 for the {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.78 + or -0.04 for the {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "0.76 + or -0.08 for the {'C': 100, 'gamma': 1, 'kernel': 'linear'}\n",
      "0.73 + or -0.05 for the {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.71 + or -0.05 for the {'C': 100, 'gamma': 1, 'kernel': 'poly'}\n",
      "0.76 + or -0.08 for the {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "0.74 + or -0.02 for the {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.73 + or -0.02 for the {'C': 100, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "0.76 + or -0.08 for the {'C': 100, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "0.77 + or -0.06 for the {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 100, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "0.76 + or -0.08 for the {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "0.78 + or -0.06 for the {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.54 + or -0.01 for the {'C': 100, 'gamma': 0.001, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "display(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270fcf9",
   "metadata": {},
   "source": [
    "From the previous analysis it seems that the comination of `C`, `gamma`and `kernel` that has the best performance is `C`= 1, `gamma`=1 and `kernel`= linear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9eef4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TO_TEST = {\n",
    "    \"SVM_lin\": SVC(kernel='linear', C= 1, gamma = 1),\n",
    "}\n",
    "\n",
    "# Define the number of splits \n",
    "NUMBER_OF_SPLITS = 5\n",
    "\n",
    "# Scoring metrics\n",
    "SCORING_METRICS = [\"accuracy\", \"precision_macro\", \"recall_macro\", \"f1_macro\"] # Metrics of interest\n",
    "\n",
    "# Create empty DataFrame to populate  the name of the classifier and the six values returned from `cross_validate()`\n",
    "results_evaluation = pd.DataFrame({\n",
    "                                    \"classifier_name\":[],\n",
    "                                    \"fit_time\": [],\n",
    "                                    \"score_time\": [],\n",
    "                                    \"test_accuracy\": [],\n",
    "                                    \"test_precision_macro\": [],\n",
    "                                    \"test_recall_macro\": [],\n",
    "                                    \"test_f1_macro\": [],\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5237f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training the classifier SVM_lin.\n",
      "The experimental setup has finished\n"
     ]
    }
   ],
   "source": [
    "#### ITERATION FOR THE EXPERIMENT\n",
    "\n",
    "for name, classifier in MODEL_TO_TEST.items():\n",
    "    \n",
    "    print(f\"Currently training the classifier {name}.\")\n",
    "\n",
    "    # Get the evaluation metrics per fold after cross-validation\n",
    "    # Note that we are passing the normalized array `X` to all classifiers\n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=NUMBER_OF_SPLITS, scoring=SCORING_METRICS)\n",
    "\n",
    "    # Average the scores among folds\n",
    "    dict_this_result = {\n",
    "                    \"classifier_name\":[name],\n",
    "                    }\n",
    "    # Populate the dictionary with the results of the cross-validation\n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_this_result[metric_name] = [ scores_cv[metric_name].mean() ]\n",
    "\n",
    "    #### Generate the results to populate the pandas.DataFrame\n",
    "    this_result = pd.DataFrame(dict_this_result)\n",
    "\n",
    "    # Append to the main dataframe with the results \n",
    "    results_evaluation = pd.concat([results_evaluation, this_result], ignore_index=True)\n",
    "\n",
    "print(\"The experimental setup has finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904bf663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/1886300855.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_svm_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.788798</td>\n",
       "      <td>0.789869</td>\n",
       "      <td>0.78725</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.872297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0             SVM  0.001711    0.002382       0.788798              0.789869   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0            0.78725       0.787109      0.872297  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"SVM\":SVC(C=1, gamma=1, kernel=\"linear\")}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_svm_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_svm_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_svm_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_svm_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1c5b2",
   "metadata": {},
   "source": [
    "### 5.5.1 Result for optimized SVM classification <a class=\"anchor\" id=\"chapter551\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb987021",
   "metadata": {},
   "source": [
    "* Accuracy = 0.789\t\n",
    "* Precision = 0.790\n",
    "* Recall = 0.787\n",
    "* F1 = 0.787\n",
    "* AUC = 0.872\n",
    "\n",
    "With hyperparameters setting: \n",
    "- C = 1\n",
    "- gamma = 1\n",
    "- kernel = linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e45cf0",
   "metadata": {},
   "source": [
    "### 5.5.2 Feature selection for SVM classification <a class=\"anchor\" id=\"chapter552\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f3612b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slope_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thalach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slope_1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbs</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restecg_0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_2.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Rank\n",
       "0           age     1\n",
       "12       cp_4.0     1\n",
       "17    slope_2.0     1\n",
       "8       sex_1.0     1\n",
       "7       sex_0.0     1\n",
       "6       oldpeak     1\n",
       "9        cp_1.0     1\n",
       "4       thalach     1\n",
       "2          chol     1\n",
       "1      trestbps     1\n",
       "5         exang     1\n",
       "11       cp_3.0     2\n",
       "16    slope_1.0     3\n",
       "18    slope_3.0     4\n",
       "3           fbs     5\n",
       "13  restecg_0.0     6\n",
       "10       cp_2.0     7\n",
       "15  restecg_2.0     8\n",
       "14  restecg_1.0     9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The logic is described above. Showing only the final dataframe with the rankings for each feature\n",
    "select_svm = RFE(SVC(kernel=\"linear\"), n_features_to_select= 11)\n",
    "X_svm = select_svm.fit_transform(data_X, data_y)\n",
    "\n",
    "selectedfeature_svm = pd.DataFrame({'Feature': list(X.columns),\n",
    "'Rank': select_svm.ranking_})\n",
    "selectedfeature_svm.sort_values(by = 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18d90a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/1429453206.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_svm_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM with RFE</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>0.80227</td>\n",
       "      <td>0.802772</td>\n",
       "      <td>0.882706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0    SVM with RFE  0.001601    0.002333       0.805191              0.807001   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0            0.80227       0.802772      0.882706  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result for RF with feature selection\n",
    "dt_model={\"SVM with RFE\":SVC(C=1, gamma=1, kernel=\"linear\")}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, X_svm, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_svm_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_svm_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_svm_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_svm_result))\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557879c",
   "metadata": {},
   "source": [
    "### 5.5.2 Result for optimized SVM with feature selection <a class=\"anchor\" id=\"chapter552\"></a>\n",
    "\n",
    "* Accuracy = 0.805\n",
    "* Precision = 0.807\n",
    "* Recall = 0.802\n",
    "* F1 = 0.803\n",
    "* AUC = 0.883\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01ad38a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404024d0",
   "metadata": {},
   "source": [
    "## 5.6 Gradient Boosted Decision Tree <a class=\"anchor\" id=\"chapter56\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d18fb3",
   "metadata": {},
   "source": [
    "Gradient Boosted Methods builds the model based on the learnings from each new training value. It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees.\n",
    "\n",
    "For gradient-boosting, parameters are coupled, so we cannot set the parameters one after the other anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60167102",
   "metadata": {},
   "source": [
    "The parameters which we need to pay attention to when we are building and optimizing a new model:\n",
    ".\n",
    "- `n_estimators` — the number of trees in the forest.\n",
    "- `learning_rate` — how much each error shall impact the rest of the trees.\n",
    "- `max_depth` — the maximum depth of the tree.\n",
    "\n",
    "But also maybe look at\n",
    "- `criterion` — the function used to measure the quality of a split.\n",
    "- `max_features` — the number of features to consider when looking for the best split.\n",
    "- `min_samples_leaf` — the minimum number of samples required to be at a leaf node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076fbbe",
   "metadata": {},
   "source": [
    "Let’s first discuss the `max_depth` parameter. The algorithm fits the error of the previous tree in the ensemble. Thus, fitting fully grown trees would be detrimental. Indeed, the first tree of the ensemble would perfectly fit (overfit) the data and thus no subsequent tree would be required, since there would be no residuals. Therefore, the tree used in gradient-boosting should have a low depth, typically between 3 to 8 levels, or few leaves. Having very weak learners at each step will help reducing overfitting.\n",
    "\n",
    "The deeper the trees, the faster the residuals will be corrected and less learners are required. Therefore, `n_estimators` should be increased if `max_depth` is lower.\n",
    "\n",
    "Finally the `learning_rate` parameter. When fitting the residuals, we would like the tree to try to correct all possible errors or only a fraction of them. The `learning-rate` allows you to control this behaviour. A small `learning-rate` value would only correct the residuals of very few samples. If a large `learning-rate` is set (e.g., 1), we would fit the residuals of all samples. So, with a very low `learning-rate`, we will need more estimators to correct the overall error. However, a too large `learning-rate` tends to obtain an overfitted ensemble, similar to having a too large tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cea1ff",
   "metadata": {},
   "source": [
    "We start with finding the approximate values for the parameters, using RandomizedSearchCV, which picks out randomized selections of the input paramteters, and tests with Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49a71e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f20f10&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f20f10&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f20f10>,\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        'n_estimators': array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check range of best parameters with randomized search CV, \n",
    "# starting with `max_depth`, `n_estimators` and `learning_rate`\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomized parameters grid \n",
    "gbc_params = {\"max_depth\": [2, 3, 4, 5, 6, 7, 8, 10, 20],\n",
    "                \"n_estimators\" : np.arange(50, 1000, 50),   # .arange = Return evenly spaced values within a given interval.\n",
    "                \"learning_rate\": loguniform(0.01, 1)\n",
    "               }\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_gbc = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                    param_distributions=gbc_params,\n",
    "                    cv=5,\n",
    "                    n_iter=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# Fit to data\n",
    "rs_gbc.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "005a56e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01930783753654713, 'max_depth': 4, 'n_estimators': 100}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best hyperparameters\n",
    "rs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05106ddf",
   "metadata": {},
   "source": [
    "`learning-rate` = 0.019, `max_depth` = 4, `n_estimators` = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c085b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f51190&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f51190&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;min_samples_leaf&#x27;: array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        &#x27;min_samples_split&#x27;: array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=GradientBoostingClassifier(), n_iter=20,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff070f51190>,\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        'min_samples_leaf': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19]),\n",
       "                                        'min_samples_split': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18]),\n",
       "                                        'n_estimators': array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding some more parameters\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Randomized parameters grid \n",
    "gbc_params = {\"n_estimators\" : np.arange(50, 1000, 50),   # .arange = Return evenly spaced values within a given interval.\n",
    "                \"max_depth\": [2, 3, 4, 5, 6, 7, 8, 10, 20],\n",
    "                \"learning_rate\": loguniform(0.01, 1),\n",
    "                \"min_samples_split\": np.arange(2, 20, 2),\n",
    "                \"min_samples_leaf\": np.arange(1, 20, 2)}\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_gbc = RandomizedSearchCV(GradientBoostingClassifier(),\n",
    "                    param_distributions=gbc_params,\n",
    "                    cv=5,\n",
    "                    n_iter=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# Fit to data\n",
    "rs_gbc.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95454f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.06055098539300347,\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 15,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best hyperparameters\n",
    "rs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f1fa0",
   "metadata": {},
   "source": [
    "`learning-rate` = 0.06, `max_depth` = 3, `n_estimators` = 100, `min_samples_leaf` = 15, `min_samples_split` = 8. \n",
    "\n",
    "Strange that `learning_rate` shifts so much, from 0.019 to 0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea1eb0b",
   "metadata": {},
   "source": [
    "We continue to narrow it down, tweeking the parameters when they move in value. Eventually ending up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2aeb4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "parameters = {\n",
    "    \"learning_rate\": [0.016, 0.017, 0.018, 0.019, 0.059, 0.06, 0.061],\n",
    "    \"max_depth\": [3,4],\n",
    "    \"n_estimators\": [100,110,130,140,150],\n",
    "    \"min_samples_leaf\": [14,15],\n",
    "    \"min_samples_split\": [2],\n",
    "    \"criterion\": ['squared_error']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b427868b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.016, 0.017, 0.018, 0.019, 0.059,\n",
       "                                           0.06, 0.061],\n",
       "                         &#x27;max_depth&#x27;: [3, 4], &#x27;min_samples_leaf&#x27;: [14, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [100, 110, 130, 140, 150]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;],\n",
       "                         &#x27;learning_rate&#x27;: [0.016, 0.017, 0.018, 0.019, 0.059,\n",
       "                                           0.06, 0.061],\n",
       "                         &#x27;max_depth&#x27;: [3, 4], &#x27;min_samples_leaf&#x27;: [14, 15],\n",
       "                         &#x27;min_samples_split&#x27;: [2],\n",
       "                         &#x27;n_estimators&#x27;: [100, 110, 130, 140, 150]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'criterion': ['squared_error'],\n",
       "                         'learning_rate': [0.016, 0.017, 0.018, 0.019, 0.059,\n",
       "                                           0.06, 0.061],\n",
       "                         'max_depth': [3, 4], 'min_samples_leaf': [14, 15],\n",
       "                         'min_samples_split': [2],\n",
       "                         'n_estimators': [100, 110, 130, 140, 150]})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GridSearchCV(gbc,parameters,cv=5)\n",
    "cv.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "50b1a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'criterion': 'squared_error', 'learning_rate': 0.019, 'max_depth': 3, 'min_samples_leaf': 15, 'min_samples_split': 2, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters are: {cv.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66702d07",
   "metadata": {},
   "source": [
    "Now we got\n",
    "- `learning_rate`: 0.019\n",
    "- `max_depth`: 3\n",
    "- `min_samples_leaf`: 15\n",
    "- `min_samples_split`: 2\n",
    "- `n_estimators`: 130\n",
    "- `criterion`: squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6359a2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/4262388154.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_gbdt_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.058615</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.795355</td>\n",
       "      <td>0.79852</td>\n",
       "      <td>0.792009</td>\n",
       "      <td>0.79243</td>\n",
       "      <td>0.873926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0            GBDT  0.058615    0.002433       0.795355               0.79852   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.792009        0.79243      0.873926  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "gbc_model={\"GBDT\":GradientBoostingClassifier(learning_rate = 0.019, max_depth = 3, n_estimators = 130, min_samples_leaf =15, min_samples_split = 2, criterion = 'squared_error')}\n",
    "\n",
    "for name, classifier in gbc_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_gbdt_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_gbdt_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    gbc_result = pd.DataFrame(dict_gbdt_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_gbdt_result))\n",
    "\n",
    "gbc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab8192",
   "metadata": {},
   "source": [
    "### 5.6.1 Result for optimized GBDT <a class=\"anchor\" id=\"chapter561\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f9cce",
   "metadata": {},
   "source": [
    "* Accuracy = 0.795\n",
    "* Precision = 0.799\n",
    "* Recall = 0.792\n",
    "* F1 = 0.792\n",
    "* AUC = 0.874\n",
    "\n",
    "With hyperparameters setting: \n",
    "- learning_rate = 0.019\n",
    "- max_depth = 3\n",
    "- n_estimators = 130\n",
    "- min_samples_leaf = 15\n",
    "- min_samples_split = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c8957",
   "metadata": {},
   "source": [
    "### 5.6.2 Feature selection for GBDT <a class=\"anchor\" id=\"chapter562\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8566f85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trestbps</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chol</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thalach</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>exang</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oldpeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex_0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sex_1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>slope_2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cp_4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>slope_1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>slope_3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>restecg_2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cp_1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>restecg_0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbs</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cp_2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cp_3.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>restecg_1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Rank\n",
       "0           age     1\n",
       "1      trestbps     1\n",
       "2          chol     1\n",
       "4       thalach     1\n",
       "5         exang     1\n",
       "6       oldpeak     1\n",
       "7       sex_0.0     1\n",
       "8       sex_1.0     1\n",
       "17    slope_2.0     1\n",
       "12       cp_4.0     1\n",
       "16    slope_1.0     2\n",
       "18    slope_3.0     3\n",
       "15  restecg_2.0     4\n",
       "9        cp_1.0     5\n",
       "13  restecg_0.0     6\n",
       "3           fbs     7\n",
       "10       cp_2.0     8\n",
       "11       cp_3.0     9\n",
       "14  restecg_1.0    10"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The logic is described above. Showing only the final dataframe with the rankings for each feature\n",
    "select_gbdt = RFE(GradientBoostingClassifier(), n_features_to_select= 10)\n",
    "X_newgbdt = select_gbdt.fit_transform(data_X, data_y)\n",
    "\n",
    "selectedfeature_gbdt = pd.DataFrame({'Feature': list(X.columns),\n",
    "                                     'Rank': select_gbdt.ranking_})\n",
    "selectedfeature_gbdt.sort_values(by = 'Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "196ec62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/2922933433.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_gbdt_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBDT with RFE</td>\n",
       "      <td>0.051834</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.806272</td>\n",
       "      <td>0.802629</td>\n",
       "      <td>0.803045</td>\n",
       "      <td>0.876937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0   GBDT with RFE  0.051834    0.002121       0.805191              0.806272   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.802629       0.803045      0.876937  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result for RF with feature selection\n",
    "gbc_model={\"GBDT with RFE\":GradientBoostingClassifier(learning_rate = 0.019, max_depth = 3, n_estimators = 130, min_samples_leaf =15, min_samples_split = 2, criterion = 'squared_error')}\n",
    "\n",
    "for name, classifier in gbc_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, X_newgbdt, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_gbdt_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_gbdt_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    gbc_result = pd.DataFrame(dict_gbdt_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_gbdt_result))\n",
    "\n",
    "gbc_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec2360",
   "metadata": {},
   "source": [
    "### 5.6.2 Result for optimized GBDT with feature selection <a class=\"anchor\" id=\"chapter562\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b86c6",
   "metadata": {},
   "source": [
    "* Accuracy = 0.805\n",
    "* Precision = 0.806\n",
    "* Recall = 0.803\n",
    "* F1 = 0.803\n",
    "* AUC = 0.877"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53555fd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9a8055",
   "metadata": {},
   "source": [
    "## 5.7 XGBoost <a class=\"anchor\" id=\"chapter57\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b54c4",
   "metadata": {},
   "source": [
    "XGBoost, which stands for Extreme Gradient Boosting (XGB), is a scalable, distributed gradient-boosted decision tree (GBDT) machine learning algorithm.\n",
    "\n",
    "It goes through a cycle: first, it tests the existing models on a validation set; then, it adds a model to make the predictions better; then, it tests this new model plus the existing models on a validation set again, and this cycle repeats till an optimal ensemble method is reached (or till the max number of iterations is reached).\n",
    "\n",
    "XGB the few algorithms that can work well on training samples of under 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9b6a7",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ed5fd",
   "metadata": {},
   "source": [
    "Imprtant parameters to consider are: `learning_rate`, `n-estimators`, `max_depth`, `subsample`, `colsample_bytree` and `gamma`. Quite similar to Gradient Boosted Tree hyperparameters.\n",
    "\n",
    "We start with `n-estimator`, `max_depth` and `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a4a1452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff051007f40&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff051007f40&gt;,\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        &#x27;n_estimators&#x27;: array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff051007f40>,\n",
       "                                        'max_depth': [2, 3, 4, 5, 6, 7, 8, 10,\n",
       "                                                      20],\n",
       "                                        'n_estimators': array([ 50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 550, 600, 650,\n",
       "       700, 750, 800, 850, 900, 950])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Randomized parameters grid \n",
    "xgb_params = {\"max_depth\": [2, 3, 4, 5, 6, 7, 8, 10, 20],\n",
    "            \"n_estimators\" : np.arange(50, 1000, 50),   # .arange = Return evenly spaced values within a given interval.\n",
    "            \"learning_rate\": loguniform(0.001, 1)\n",
    "            }\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_xgb = RandomizedSearchCV(XGBClassifier(),\n",
    "                    param_distributions=xgb_params,\n",
    "                    cv=5,\n",
    "                    n_iter=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# Fit to data\n",
    "rs_xgb.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ee063b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.014899847475658243, 'max_depth': 3, 'n_estimators': 400}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best hyperparameters\n",
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad5836",
   "metadata": {},
   "source": [
    "`learning_rate` = 0.015, `max_depth` = 3, `n_estimators` = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b850269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the optimized model and printing the results\n",
    "models = {\"XGBoost\": XGBClassifier(\n",
    "        learning_rate=0.015,\n",
    "        max_depth=3, \n",
    "        n_estimators=400)\n",
    "        }\n",
    "\n",
    "for name, classifier in models.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_xgb_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_xgb_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    this_result = pd.DataFrame(dict_xgb_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e681c388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.243002</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.782077</td>\n",
       "      <td>0.787143</td>\n",
       "      <td>0.778768</td>\n",
       "      <td>0.778213</td>\n",
       "      <td>0.855995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0         XGBoost  0.243002    0.004603       0.782077              0.787143   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.778768       0.778213      0.855995  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791707c4",
   "metadata": {},
   "source": [
    "Not too bad. Then we continue with `subsample`, `colsample_bytree` and `gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e758c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1778, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 246, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1778, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 246, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 1778, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/Users/orka/opt/anaconda3/lib/python3.9/site-packages/xgboost/core.py\", line 246, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/orka/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.7820765         nan        nan        nan        nan\n",
      " 0.77557377 0.76896175        nan 0.77240437 0.79530055        nan\n",
      "        nan        nan        nan        nan 0.77218579 0.78218579\n",
      "        nan 0.78557377]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9, 1.0,\n",
       "                                                             1.1, 1.2],\n",
       "                                        &#x27;gamma&#x27;: [0, 1, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.015],\n",
       "                                        &#x27;max_depth&#x27;: [3],\n",
       "                                        &#x27;n_estimators&#x27;: [350, 400, 450],\n",
       "                                        &#x27;subsample&#x27;: array([0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9, 1.0,\n",
       "                                                             1.1, 1.2],\n",
       "                                        &#x27;gamma&#x27;: [0, 1, 5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.015],\n",
       "                                        &#x27;max_depth&#x27;: [3],\n",
       "                                        &#x27;n_estimators&#x27;: [350, 400, 450],\n",
       "                                        &#x27;subsample&#x27;: array([0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, gamma=None,\n",
       "              gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=20,\n",
       "                   param_distributions={'colsample_bytree': [0.7, 0.8, 0.9, 1.0,\n",
       "                                                             1.1, 1.2],\n",
       "                                        'gamma': [0, 1, 5],\n",
       "                                        'learning_rate': [0.015],\n",
       "                                        'max_depth': [3],\n",
       "                                        'n_estimators': [350, 400, 450],\n",
       "                                        'subsample': array([0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Randomized parameters grid \n",
    "xgb_params = {\"subsample\": np.arange(0.2, 2, 0.2),\n",
    "            \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0, 1.1, 1.2],\n",
    "            \"gamma\": [0,1,5],\n",
    "            \"max_depth\": [3],\n",
    "            \"n_estimators\" : [350, 400, 450],   \n",
    "            \"learning_rate\": [0.015]\n",
    "            }\n",
    "\n",
    "# Instantiate RandomizedSearchCV\n",
    "rs_xgb = RandomizedSearchCV(XGBClassifier(),\n",
    "                    param_distributions=xgb_params,\n",
    "                    cv=5,\n",
    "                    n_iter=20,\n",
    "                    verbose=1)\n",
    "\n",
    "# Fit to data\n",
    "rs_xgb.fit(data_X, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a41d4ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.2,\n",
       " 'n_estimators': 400,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.015,\n",
       " 'gamma': 0,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best hyperparameters\n",
    "rs_xgb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7da0b2",
   "metadata": {},
   "source": [
    "`subsample` = 0.4, `learning_rate` = 0.015, `max_depth` = 3, `n_estimators` = 400, `gamma` = 0, `colsample_bytree` = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f626fa6",
   "metadata": {},
   "source": [
    "Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7becf0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.179515</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.78541</td>\n",
       "      <td>0.787298</td>\n",
       "      <td>0.782283</td>\n",
       "      <td>0.78254</td>\n",
       "      <td>0.868417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0         XGBoost  0.179515    0.004632        0.78541              0.787298   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.782283        0.78254      0.868417  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print out the result\n",
    "dt_model={\"XGBoost\":XGBClassifier(learning_rate=0.015, max_depth=3, n_estimators=400, colsample_bytree=0.9, subsample=0.4, gamma=0)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_xgb_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_xgb_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    dt_result = pd.DataFrame(dict_xgb_result)\n",
    "\n",
    "dt_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae92059",
   "metadata": {},
   "source": [
    "A little bit better. Let's see if we can tweek it a bit more. \n",
    "\n",
    "We continue to look into the various parameters, testing the ones that change. Eventually ending up with the last optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27fbcd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.059000000000000004, 'max_depth': 3, 'n_estimators': 262, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "parameters = {\n",
    "    \"learning_rate\": np.arange(0.055, 0.065, 0.001),\n",
    "    \"max_depth\": [3],\n",
    "    \"n_estimators\": [260,261,262],\n",
    "    \"subsample\": [0.7, 0.8, 0.9],\n",
    "    \"gamma\": [1],\n",
    "    \"colsample_bytree\": [0.9]\n",
    "    }\n",
    "\n",
    "cv = GridSearchCV(xgb,parameters,cv=5)\n",
    "cv.fit(data_X, data_y)\n",
    "\n",
    "print(f'Best parameters are: {cv.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "307c139a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/138931542.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_xgb_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.772131</td>\n",
       "      <td>0.776122</td>\n",
       "      <td>0.768463</td>\n",
       "      <td>0.76844</td>\n",
       "      <td>0.852184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0         XGBoost  0.079934    0.003883       0.772131              0.776122   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.768463        0.76844      0.852184  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the optimized model and printing the results\n",
    "models = {\"XGBoost\": XGBClassifier(\n",
    "        learning_rate=0.06,\n",
    "        max_depth=3, \n",
    "        n_estimators=261,\n",
    "        subsample=0.8,\n",
    "        gamma=1,\n",
    "        colsample_bytree=0.9)\n",
    "        }\n",
    "\n",
    "for name, classifier in models.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_xgb_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_xgb_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    this_result = pd.DataFrame(dict_xgb_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_xgb_result))\n",
    "\n",
    "this_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df21635",
   "metadata": {},
   "source": [
    "### 5.7.1 Result for optimized XGBoost <a class=\"anchor\" id=\"chapter571\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa2252d",
   "metadata": {},
   "source": [
    "* Accuracy = 0.772\n",
    "* Precision = 0.776\n",
    "* Recall = 0.768\t\n",
    "* F1 = 0.768\n",
    "* AUC = 0.852\n",
    "\n",
    "With hyperparameters setting: \n",
    "- learning_rate = 0.06\n",
    "- max_depth = 3\n",
    "- n_estimators = 261\n",
    "- subsample = 0.8\n",
    "- gamma = 1\n",
    "- colsample_bytree = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dcc015",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10d9b2",
   "metadata": {},
   "source": [
    "## 5.8 Multi-layer Perceptron <a class=\"anchor\" id=\"chapter58\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f74ed1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5k/4cpsyd4915ld3szp5dw41nq40000gn/T/ipykernel_18189/1208698156.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_finalresult = df_finalresult.append(pd.DataFrame(dict_mlp_result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>8.444097</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.729563</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.728688</td>\n",
       "      <td>0.825451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier_name  fit_time  score_time  test_accuracy  test_precision_macro  \\\n",
       "0      Perceptron  8.444097    0.015401       0.729563              0.728884   \n",
       "\n",
       "   test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0           0.729848       0.728688      0.825451  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model={\"Perceptron\":MLPClassifier(hidden_layer_sizes=(1000, 1000, 1000), max_iter=2500)}\n",
    "\n",
    "for name, classifier in dt_model.items():\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    scores_cv = cross_validate(classifier, data_X, data_y, cv=5, scoring=metrics)\n",
    "\n",
    "    dict_mlp_result = {\"classifier_name\":[name],}\n",
    "    \n",
    "    for metric_name, score_per_fold in scores_cv.items():\n",
    "        dict_mlp_result[metric_name] = [scores_cv[metric_name].mean()]\n",
    "\n",
    "    this_result = pd.DataFrame(dict_mlp_result)\n",
    "    df_finalresult = df_finalresult.append(pd.DataFrame(dict_mlp_result))\n",
    "\n",
    "this_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0855e2",
   "metadata": {},
   "source": [
    "### 5.8.1 Result for Multi-layer Perceptron <a class=\"anchor\" id=\"chapter581\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e71a3",
   "metadata": {},
   "source": [
    "- **Accuracy** : 0.730\n",
    "- **Precision**: 0.729\n",
    "- **Recall**: 0.730\n",
    "- **F1** : 0.729\n",
    "- **AUC** : 0.825"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd80ae5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c790ab",
   "metadata": {},
   "source": [
    "# 6 Result optimization <a class=\"anchor\" id=\"chapter6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e2716",
   "metadata": {},
   "source": [
    "The original baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99dffe1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.778852</td>\n",
       "      <td>0.779359</td>\n",
       "      <td>0.776631</td>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.882522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.683224</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0.679004</td>\n",
       "      <td>0.678981</td>\n",
       "      <td>0.679004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.071501</td>\n",
       "      <td>0.010982</td>\n",
       "      <td>0.769071</td>\n",
       "      <td>0.770251</td>\n",
       "      <td>0.767226</td>\n",
       "      <td>0.766973</td>\n",
       "      <td>0.852734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.762568</td>\n",
       "      <td>0.763770</td>\n",
       "      <td>0.763814</td>\n",
       "      <td>0.761660</td>\n",
       "      <td>0.807423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.775683</td>\n",
       "      <td>0.777530</td>\n",
       "      <td>0.777691</td>\n",
       "      <td>0.774883</td>\n",
       "      <td>0.852366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.047196</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.765519</td>\n",
       "      <td>0.767636</td>\n",
       "      <td>0.760961</td>\n",
       "      <td>0.761306</td>\n",
       "      <td>0.840292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.030101</td>\n",
       "      <td>0.003371</td>\n",
       "      <td>0.772186</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.769545</td>\n",
       "      <td>0.768755</td>\n",
       "      <td>0.822226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>0.742459</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.738692</td>\n",
       "      <td>0.736954</td>\n",
       "      <td>0.796248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier_name  fit_time  score_time  test_accuracy  \\\n",
       "0  Logistic Regression  0.003354    0.002045       0.778852   \n",
       "1                   DT  0.000802    0.001647       0.683224   \n",
       "2                   RF  0.071501    0.010982       0.769071   \n",
       "3                  KNN  0.000168    0.009762       0.762568   \n",
       "4                  SVM  0.002743    0.003600       0.775683   \n",
       "5                 GBDT  0.047196    0.002179       0.765519   \n",
       "6              XGBoost  0.030101    0.003371       0.772186   \n",
       "7             AdaBoost  0.035655    0.008534       0.742459   \n",
       "\n",
       "   test_precision_macro  test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0              0.779359           0.776631       0.776390      0.882522  \n",
       "1              0.682273           0.679004       0.678981      0.679004  \n",
       "2              0.770251           0.767226       0.766973      0.852734  \n",
       "3              0.763770           0.763814       0.761660      0.807423  \n",
       "4              0.777530           0.777691       0.774883      0.852366  \n",
       "5              0.767636           0.760961       0.761306      0.840292  \n",
       "6              0.776667           0.769545       0.768755      0.822226  \n",
       "7              0.744710           0.738692       0.736954      0.796248  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a6fbf4",
   "metadata": {},
   "source": [
    "The optimized results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2a2e857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision_macro</th>\n",
       "      <th>test_recall_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.791967</td>\n",
       "      <td>0.794689</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.789260</td>\n",
       "      <td>0.881489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR with RFE</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.805301</td>\n",
       "      <td>0.806232</td>\n",
       "      <td>0.803749</td>\n",
       "      <td>0.803491</td>\n",
       "      <td>0.894094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.765574</td>\n",
       "      <td>0.778168</td>\n",
       "      <td>0.757116</td>\n",
       "      <td>0.757072</td>\n",
       "      <td>0.809711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT with RFE</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.752514</td>\n",
       "      <td>0.752632</td>\n",
       "      <td>0.753489</td>\n",
       "      <td>0.751558</td>\n",
       "      <td>0.818561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.563940</td>\n",
       "      <td>0.074595</td>\n",
       "      <td>0.765628</td>\n",
       "      <td>0.767169</td>\n",
       "      <td>0.763019</td>\n",
       "      <td>0.762928</td>\n",
       "      <td>0.879638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF with RFE</td>\n",
       "      <td>0.556614</td>\n",
       "      <td>0.074075</td>\n",
       "      <td>0.775519</td>\n",
       "      <td>0.776366</td>\n",
       "      <td>0.772424</td>\n",
       "      <td>0.773035</td>\n",
       "      <td>0.881546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.782186</td>\n",
       "      <td>0.781741</td>\n",
       "      <td>0.781901</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.845617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.788798</td>\n",
       "      <td>0.789869</td>\n",
       "      <td>0.787250</td>\n",
       "      <td>0.787109</td>\n",
       "      <td>0.872297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM with RFE</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>0.802270</td>\n",
       "      <td>0.802772</td>\n",
       "      <td>0.882706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBDT</td>\n",
       "      <td>0.058615</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.795355</td>\n",
       "      <td>0.798520</td>\n",
       "      <td>0.792009</td>\n",
       "      <td>0.792430</td>\n",
       "      <td>0.873926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GBDT with RFE</td>\n",
       "      <td>0.051834</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.805191</td>\n",
       "      <td>0.806272</td>\n",
       "      <td>0.802629</td>\n",
       "      <td>0.803045</td>\n",
       "      <td>0.876937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>0.003883</td>\n",
       "      <td>0.772131</td>\n",
       "      <td>0.776122</td>\n",
       "      <td>0.768463</td>\n",
       "      <td>0.768440</td>\n",
       "      <td>0.852184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>8.444097</td>\n",
       "      <td>0.015401</td>\n",
       "      <td>0.729563</td>\n",
       "      <td>0.728884</td>\n",
       "      <td>0.729848</td>\n",
       "      <td>0.728688</td>\n",
       "      <td>0.825451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       classifier_name  fit_time  score_time  test_accuracy  \\\n",
       "0  Logistic Regression  0.000593    0.001814       0.791967   \n",
       "0          LR with RFE  0.000547    0.001841       0.805301   \n",
       "0        Decision Tree  0.000714    0.002301       0.765574   \n",
       "0          DT with RFE  0.000975    0.002407       0.752514   \n",
       "0        Random Forest  0.563940    0.074595       0.765628   \n",
       "0          RF with RFE  0.556614    0.074075       0.775519   \n",
       "0                  KNN  0.000262    0.007930       0.782186   \n",
       "0                  SVM  0.001711    0.002382       0.788798   \n",
       "0         SVM with RFE  0.001601    0.002333       0.805191   \n",
       "0                 GBDT  0.058615    0.002433       0.795355   \n",
       "0        GBDT with RFE  0.051834    0.002121       0.805191   \n",
       "0              XGBoost  0.079934    0.003883       0.772131   \n",
       "0           Perceptron  8.444097    0.015401       0.729563   \n",
       "\n",
       "   test_precision_macro  test_recall_macro  test_f1_macro  test_roc_auc  \n",
       "0              0.794689           0.789388       0.789260      0.881489  \n",
       "0              0.806232           0.803749       0.803491      0.894094  \n",
       "0              0.778168           0.757116       0.757072      0.809711  \n",
       "0              0.752632           0.753489       0.751558      0.818561  \n",
       "0              0.767169           0.763019       0.762928      0.879638  \n",
       "0              0.776366           0.772424       0.773035      0.881546  \n",
       "0              0.781741           0.781901       0.780702      0.845617  \n",
       "0              0.789869           0.787250       0.787109      0.872297  \n",
       "0              0.807001           0.802270       0.802772      0.882706  \n",
       "0              0.798520           0.792009       0.792430      0.873926  \n",
       "0              0.806272           0.802629       0.803045      0.876937  \n",
       "0              0.776122           0.768463       0.768440      0.852184  \n",
       "0              0.728884           0.729848       0.728688      0.825451  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.633 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.705 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.633 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=2, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0, splitter=random;, score=0.633 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=sqrt, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=gini, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.754 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=2, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=best;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=entropy, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=5, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.533 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.567 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=best;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.750 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.25, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 2/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.541 total time=   0.0s\n",
      "[CV 4/5] END criterion=log_loss, max_depth=10, max_features=auto, min_weight_fraction_leaf=0.5, splitter=best;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.25, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=best;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END criterion=log_loss, max_depth=10, max_features=log2, min_weight_fraction_leaf=0.5, splitter=random;, score=0.541 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "df_finalresult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f34cbd",
   "metadata": {},
   "source": [
    "## 6.1 Choice of best optimizer <a class=\"anchor\" id=\"chapter61\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a469b9",
   "metadata": {},
   "source": [
    "Looking at the measures for our tested classifiers, we choose **Logistic Regression** to implement in aiHeart. Using this model, we experimented on iteratively dropping the weakest features based on the results from RFE. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b06da12d",
   "metadata": {},
   "source": [
    "|   \t|   Accuracy\t|   Precision |   Recall\t|   F1\t|   AUC\t|\n",
    "|:-\t|---\t|---\t|---\t|---\t|---\t|\n",
    "|   1. Logistic Regression (without ca and thal)\t|  0.791967 \t|  0.794689 \t|   0.789388\t|   0.78926\t|   0.881489\t|\n",
    "|   2. Logistic Regression (without ca and thal and fbs)\t|   0.798525\t|   0.800595\t|   0.79599\t|   0.796083\t|   0.88454\t|\n",
    "|   3. Logistic Regression (without ca and thal and fbs and restecg)\t|   0.81847\t|   0.81938\t|  0.815965 \t|  0.816457 \t|   0.888715\t|\n",
    "|  4. Logistic Regression (without ca and thal and fbs and restecg and cp)\t|   0.782186\t|   0.78443\t|   0.780335\t|   0.779873\t|   0.855529\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f34a5",
   "metadata": {},
   "source": [
    "Based on these results, we decided to use the third model in this table and drop the features `fbs` and `restecg`.\n",
    "\n",
    "Refer to notebook `aiHeart: Final Classifier` for implementation of our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca05a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e973fc2e000e46a03caede90db88e0085b59ce3854a1387ca28cfb55b1d1397a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
